## 一、 安装运行kafka

#### 1、安装JDK

&emsp;&emsp;1) 下载jdk，安装  
&emsp;&emsp;2) 添加和修改系统变量  
&emsp;&emsp;3) java -version测试是否安装成功

#### 2、安装zookeeper

&emsp;&emsp;1) 解压，修改conf/zoo.cfg文件  
&emsp;&emsp;&emsp;&emsp;dataDir=D:/kafka/zookeeper-3.4.12/dataDir  
&emsp;&emsp;&emsp;&emsp;dataLogDir=

&emsp;&emsp;2) 系统变量（和java一样）  
&emsp;&emsp;&emsp;&emsp;添加ZOOKEEPER_PATH=D:/kafka/zookeeper-3.4.12  
&emsp;&emsp;&emsp;&emsp;在path后添加%ZOOKEEPER%/bin

&emsp;&emsp;3) 在zookeeper解压目录中打开cmd窗口，命令：zkserver    //如果不行，双击打开zkServer.bat也可以运行

#### 3、安装kafka

&emsp;&emsp;解压，修改config/server.properties

```cpp
        log.dirs=D:/kafka/kafka_2.11-2.1.0/logs
```

#### 4、测试

```cpp
1、打开动物园管理者
    >zkserver
2、打开kafka，
    >.\bin\windows\kafka-server-start.bat .\config\server.properties
3、创建主题（创建完后，不会保持运行状态）
    >kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test.topic
4、创建生产者
    >kafka-console-producer.bat --broker-list localhost:9092 --topic test.topic
5、创建消费者
    >kafka-console-consumer.bat --bootstrap-server localhost:9092 --from-beginning --topic test.topic
6、然后在生产者端发送消息，消费者端可以接受到消息即可
```

> 安装完成后，可以编译librdkafa并且运行其自带的实例

## 二、编译librdkafka

#### 1、下载librdkafka和编译好的openssl库

#### 2、打开librdkafka的win32工程：
```cpp
        1、包含openssl库和头文件目录  
        2、工具->选项->包管理器->程序源包，勾选nuget.org  
        3、遇到无法识别u32等问题：
            将u32改为对应类型，将if的一个语句使用{}扩起来
            运行消费者实例，可以和之前安装的kafka通信即可。
```

#### 3、编译过程中遇到的问题，总结：
```cpp
        1、使用网上的例子，发现头文件不一样，无法包含。
        2、在librdkafka工程中搜索头文件，感觉不同平台头文件不一样，将没有的头文件换成windows下的，比如<time.h>改为<wintime.h>。
```

```cpp
        百度，自己写了一个<unistd.h>，并且修改timeval  
        缺少库，根据头文件名librdkafkacpp.h猜测库名
```

## 三、接口/代码

#### 生产者

```cpp
#ifndef __KAFKA_PRODUCE_H
#define __KAFKA_PRODUCE_H

#include <string>
#include <iostream>
#include "kafka/rdkafkacpp.h"

class KafkaProduce :public RdKafka::EventCb, public RdKafka::DeliveryReportCb
{
public:
    KafkaProduce();
    ~KafkaProduce();
public:
    void event_cb(RdKafka::Event &event);
    void dr_cb(RdKafka::Message &message);
public:
    bool Init(const char*  topic, const char* broker);
    void ProduceMsg(std::string msg);
    void Destroy();
private:
    std::string mTopic;
    std::string mBroker;
private:
    RdKafka::Conf*  mConf;
    RdKafka::Conf*  mTConf;
    RdKafka::Producer*  mProducer;
    RdKafka::Topic *  mKTopic;
    int32_t           mPartition;
};

#endif


#include "KafkaProduce.h"
#include <iostream>

KafkaProduce::KafkaProduce()
{
    mConf = NULL;
    mTConf = NULL;
    mProducer = NULL;
    mKTopic = NULL;
}


KafkaProduce::~KafkaProduce()
{
    Destroy();
}

void KafkaProduce::event_cb(RdKafka::Event &event)
{
    switch (event.type())
    {
    case RdKafka::Event::EVENT_ERROR:
        std::cerr << "ERROR (" << RdKafka::err2str(event.err()) << "): " <<
            event.str() << std::endl;
        if (event.err() == RdKafka::ERR__ALL_BROKERS_DOWN)
            ;// run = false;
        break;

    case RdKafka::Event::EVENT_STATS:
        std::cerr << "\"STATS\": " << event.str() << std::endl;
        break;

    case RdKafka::Event::EVENT_LOG:
        fprintf(stderr, "LOG-%i-%s: %s\n",
            event.severity(), event.fac().c_str(), event.str().c_str());
        break;

    default:
        std::cerr << "EVENT " << event.type() <<
            " (" << RdKafka::err2str(event.err()) << "): " <<
            event.str() << std::endl;
        break;
    }
}

void KafkaProduce::dr_cb(RdKafka::Message &message)
{
    std::cout << "Message delivery for (" << message.len() << " bytes): " <<
        message.errstr() << std::endl;
    if (message.key())
        std::cout << "Key: " << *(message.key()) << ";" << std::endl;
}

bool KafkaProduce::Init(const char*  topic, const char* broker)
{
    mBroker = broker;
    mTopic = topic;
    std::string errstr;
    std::string mode = "P";
    mPartition = RdKafka::Topic::PARTITION_UA;
    mConf = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
    mTConf = RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC);

    mConf->set("metadata.broker.list", mBroker, errstr);


    mConf->set("event_cb", (RdKafka::EventCb*)this, errstr);

    /* Set delivery report callback */
    mConf->set("dr_cb", (RdKafka::DeliveryReportCb*)this, errstr);
    mProducer = RdKafka::Producer::create(mConf, errstr);

    if (!mProducer)
    {
        return false;
    }
    std::cout << "% Created producer " << mProducer->name() << std::endl;

    /*
    * Create topic handle.
    */
    mKTopic = RdKafka::Topic::create(mProducer, mTopic,
        mTConf, errstr);
    if (!topic) {
        std::cerr << "Failed to create topic: " << errstr << std::endl;
        return false;
    }
    return true;
}

void KafkaProduce::ProduceMsg(std::string msg)
{
    mProducer->poll(0);
    RdKafka::ErrorCode resp =
        mProducer->produce(mKTopic, mPartition,
        RdKafka::Producer::RK_MSG_COPY /* Copy payload */,
        const_cast<char *>(msg.c_str()), msg.size(),
        NULL, NULL);
    if (resp != RdKafka::ERR_NO_ERROR)
        std::cerr << "% Produce failed: " <<
        RdKafka::err2str(resp) << std::endl;
    else
        std::cerr << "% Produced message (" << msg.size() << " bytes)" <<
        std::endl;

    mProducer->poll(0);
}

void KafkaProduce::Destroy()
{
    if (mProducer)
    {
        while (mProducer->outq_len() > 0)
        {
            //std::cerr << "Waiting for " << mProducer->outq_len() << std::endl;
            mProducer->poll(1000);
        }
    }
    if (mKTopic)
    {
        delete mKTopic;
        mKTopic = NULL;
    }
    if (mProducer)
    {
        delete mProducer;
        mProducer = NULL;
    }
    if (mTConf)
    {
        delete mTConf;
        mTConf = NULL;
    }
    if (mConf)
    {
        delete mConf;
        mConf = NULL;
    }
}


void TestProduce()//最好把此函数也封装提取成一个接口
{
    KafkaProduce produce;
    const char brokers = 127.0.0.19000;
    const char topic = TOPIC_TEST;
    if (!produce.Init(topic, brokers))
    {
        return;
    }

     Read messages from stdin and produce to broker.

    for (stdstring line; stdgetline(stdcin, line);)
    {
        if (line.size() == 0)
        {
            break;
        }
        produce.ProduceMsg(line);
    }
    produce.Destroy();
}



项目实际使用

KafkaProduce::KafkaProduce()
{
    mConf = NULL;
    mTConf = NULL;
    mProducer = NULL;
    mKTopic = NULL;
}

void KafkaProduce::sendMsg(QString str)
{
    QDomDocument doc;
    QFile file("./kafka.xml");
    doc.setContent(&file);
    QDomElement root=doc.documentElement();;
    QDomNode node=root.firtChld();

    std::string brokers=root.attrbute("ip").toStdString();
    std::string topic=root.attrbute("topic").toStdString();

    Init(topic.data(),brokers.data());

    std::string msg=str.toStdString();

    mProducer->poll(0);
    RdKafka::ErrorCode resp =
        mProducer->produce(mKTopic, mPartition,
        RdKafka::Producer::RK_MSG_COPY /* Copy payload */,
        const_cast<char *>(msg.c_str()), msg.size(),
        NULL, NULL);
    if (resp != RdKafka::ERR_NO_ERROR)
        std::cerr << "% Produce failed: " <<
        RdKafka::err2str(resp) << std::endl;
    else
        std::cerr << "% Produced message (" << msg.size() << " bytes)" <<
        std::endl;

    mProducer->poll(0);
}
```

```cpp

//使用
KafkaProduce kafka;
QString msg="hello kafka";
kafka.sendMsg(msg);
```

#### 消费者

```cpp
#ifndef  __KAFKA_CONSUMER_H
#define  __KAFKA_CONSUMER_H

#include <string>
#include <iostream>
#include "kafka/rdkafkacpp.h"

#ifdef _MSC_VER
#include <atltime.h>
#elif _AIX
#include <unistd.h>
#else
#include <getopt.h>
#include <unistd.h>
#endif

class KafkaConsumer :public RdKafka::RebalanceCb, public RdKafka::EventCb
{
public:
    KafkaConsumer();
    ~KafkaConsumer();
public:
    bool Init(const char*  topic, const char* broker, const char* group_id);
    void DoConsumeMsg();
    void Destroy();
    void MsgConsume(RdKafka::Message* message);
public:
    void event_cb(RdKafka::Event &event);
    void rebalance_cb(RdKafka::KafkaConsumer *consumer,
        RdKafka::ErrorCode err,
        std::vector<RdKafka::TopicPartition*> &partitions);
private:
    std::string mTopic;
    std::string mBroker;
private:
    RdKafka::KafkaConsumer* mConsumer;
};

#endif



#include "KafkaConsumer.h"


KafkaConsumer::KafkaConsumer()
{
    mConsumer = NULL;
}


KafkaConsumer::~KafkaConsumer()
{
}

bool KafkaConsumer::Init(const char*  topic, const char* broker, const char* group_id)
{
    std::string errstr;
    std::vector<std::string> topics;
    RdKafka::Conf *conf = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
    RdKafka::Conf *tconf = RdKafka::Conf::create(RdKafka::Conf::CONF_TOPIC);
    conf->set("rebalance_cb", (RdKafka::RebalanceCb*)this, errstr);

    if (conf->set("group.id", group_id, errstr) != RdKafka::Conf::CONF_OK) {
        std::cerr << errstr << std::endl;
        return false;
    }
    topics.push_back(topic);
    conf->set("metadata.broker.list", broker, errstr);

    conf->set("event_cb", (RdKafka::EventCb*)this, errstr);
    conf->set("default_topic_conf", tconf, errstr);
    delete tconf;

    /*
    * Create consumer using accumulated global configuration.
    */
    mConsumer = RdKafka::KafkaConsumer::create(conf, errstr);
    if (!mConsumer) {
        std::cerr << "Failed to create consumer: " << errstr << std::endl;
        return false;
    }

    delete conf;

    std::cout << "% Created consumer " << mConsumer->name() << std::endl;


    /*
    * Subscribe to topics
    */
    RdKafka::ErrorCode err = mConsumer->subscribe(topics);
    if (err) {
        std::cerr << "Failed to subscribe to " << topics.size() << " topics: "
            << RdKafka::err2str(err) << std::endl;
        return false;
    }
    return true;
}

void KafkaConsumer::DoConsumeMsg()
{
    while (1) {
        RdKafka::Message *msg = mConsumer->consume(1000);
        MsgConsume(msg);
        delete msg;
    }
}

void KafkaConsumer::event_cb(RdKafka::Event &event)
{
    switch (event.type())
    {
    case RdKafka::Event::EVENT_ERROR:
        std::cerr << "ERROR (" << RdKafka::err2str(event.err()) << "): " <<
            event.str() << std::endl;
        if (event.err() == RdKafka::ERR__ALL_BROKERS_DOWN)
            ;// run = false;
        break;

    case RdKafka::Event::EVENT_STATS:
        std::cerr << "\"STATS\": " << event.str() << std::endl;
        break;

    case RdKafka::Event::EVENT_LOG:
        fprintf(stderr, "LOG-%i-%s: %s\n",
            event.severity(), event.fac().c_str(), event.str().c_str());
        break;

    case RdKafka::Event::EVENT_THROTTLE:
        std::cerr << "THROTTLED: " << event.throttle_time() << "ms by " <<
            event.broker_name() << " id " << (int)event.broker_id() << std::endl;
        break;

    default:
        std::cerr << "EVENT " << event.type() <<
            " (" << RdKafka::err2str(event.err()) << "): " <<
            event.str() << std::endl;
        break;
    }
}

void KafkaConsumer::rebalance_cb(RdKafka::KafkaConsumer *consumer,
    RdKafka::ErrorCode err,
    std::vector<RdKafka::TopicPartition*> &partitions)
{
    std::cerr << "RebalanceCb: " << RdKafka::err2str(err) << ": ";

    //part_list_print(partitions);

    if (err == RdKafka::ERR__ASSIGN_PARTITIONS) {
        consumer->assign(partitions);
        //partition_cnt = (int)partitions.size();
    }
    else {
        consumer->unassign();
        //partition_cnt = 0;
    }
    //eof_cnt = 0;
}

void KafkaConsumer::MsgConsume(RdKafka::Message* message)
{
    switch (message->err()) {
    case RdKafka::ERR__TIMED_OUT:
        break;

    case RdKafka::ERR_NO_ERROR:
        /* Real message */
            printf("%.*s\n",
                static_cast<int>(message->len()),
                static_cast<const char *>(message->payload()));
        break;

    case RdKafka::ERR__PARTITION_EOF:
        /* Last message */
        //if (exit_eof && ++eof_cnt == partition_cnt) {
        //  std::cerr << "%% EOF reached for all " << partition_cnt <<
        //      " partition(s)" << std::endl;
        //  //run = false;
        //}
        break;

    case RdKafka::ERR__UNKNOWN_TOPIC:
    case RdKafka::ERR__UNKNOWN_PARTITION:
        std::cerr << "Consume failed: " << message->errstr() << std::endl;
        //run = false;
        break;

    default:
        /* Errors */
        std::cerr << "Consume failed: " << message->errstr() << std::endl;
        //run = false;
    }
}

void KafkaConsumer::Destroy()
{
    if (mConsumer)
    {
        delete mConsumer;
        mConsumer = NULL;
    }
}


void TestConsumer()//最好把此函数也封装提取成一个接口
{
    KafkaConsumer consumer;
    const char* brokers = "127.0.0.1:9000";
    const char* topic = "TOPIC_TEST";
    if (!consumer.Init(topic, brokers,"0"))
    {
        return;
    }
    /*
    * Read messages from stdin and produce to broker.
    */
    consumer.DoConsumeMsg();
    consumer.Destroy();
}

```


